import torch
import os
import numpy as np
from crl_kino.env import DifferentialDriveEnv, DifferentialDriveGym
from crl_kino.planner.rrt_rl import RRT_RL
from crl_kino.policy.rl_policy import load_policy, policy_forward
from matplotlib import pyplot as plt

import pickle


def samplesg():
    # sample valid start and goal
    valid = False
    while not valid:
        start = np.random.uniform(-20, 20, (2, ))
        goal = np.random.uniform(-20, 20, (2, ))

        start_dis = np.sqrt(((start - obs[:, :])**2).sum(1))

        goal_dis = np.sqrt(((goal - obs[:, :])**2).sum(1))

        if start_dis.min() > 2.5 and goal_dis.min() > 2.5:
            valid = True


    start = np.concatenate([start, np.zeros((3, ))])
    goal = np.concatenate([goal, np.zeros((3, ))])

    return start, goal

def data_collection():
    # collect data generated by local planner
    model_path =os.path.dirname(__file__)+'/data/net/end2end/ddpg/policy.pth'


    obs_list = []
    cost_list = []

    for maps in range(20):
        print("sampling: {}".format(maps))
        obstacles_list = pickle.load(open(os.path.dirname(__file__)+'/data/obstacles/obs_list_list.pkl', 'rb'))[maps:maps+1]

        env = DifferentialDriveGym(obs_list_list=obstacles_list)

        policy = load_policy(env, [1024, 512, 512, 512], model_path)



        for _ in range(100):
            obs = env.reset()

            #env.render()

            obs_epi = []
            obs_epi.append(obs)

            t = 0
            while True:
                action = policy_forward(policy, obs, eps=0.05)
                obs, reward, done, info = env.step(action[0])
                env.render()
                obs_epi.append(obs)

                t += 1

                if done:
                    break
            
            goal_dist = np.linalg.norm(env.state[:2]-env.goal[:2])

            if goal_dist > 1:
                print("not arrive")
                costs = np.ones([t+1, ])*150
            else:
                costs = np.flip(np.arange(t+1))
                print("arrive")
            obs_list.append(np.array(obs_epi))
            cost_list.append(costs*0.2)


        
    obs_np = np.concatenate(obs_list)
    costs_np = np.concatenate(cost_list)

    return obs_np, costs_np

obs_np, costs_np = data_collection()

np.save("obs.npy", obs_np)
np.save("costs.npy", costs_np)